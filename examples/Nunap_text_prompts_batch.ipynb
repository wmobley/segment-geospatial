{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cTdOleQ2J3tL"
   },
   "source": [
    "# Batch segmentation with text prompts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X1jbi4GdJ3tO"
   },
   "source": [
    "## Enable Jupyter Lab Leaflet\n",
    "\n",
    "Run the following cell and reload  the page to enable the Jupyter Lab Leaflet extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X2e7qFKLJ3tO"
   },
   "outputs": [],
   "source": [
    "!jupyter labextension enable jupyter-leaflet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "-GXWfTyzJ3tQ",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import leafmap\n",
    "from samgeo import tms_to_geotiff, split_raster, SamGeo\n",
    "from samgeo.text_sam import LangSAM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FTfUmCWtJ3tQ"
   },
   "source": [
    "## Create an interactive map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XHi3Q1LpJ3tQ"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ae09793e50454abc70940cfab0e341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[60.8965, -162.458], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'z…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = leafmap.Map(center=[60.89650, -162.4580], zoom=17, height=\"800px\")\n",
    "m.add_basemap(\"SATELLITE\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RGIO1-I0J3tR"
   },
   "source": [
    "## Download a sample image\n",
    "\n",
    "Pan and zoom the map to select the area of interest. Use the draw tools to draw a polygon or rectangle on the map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bSzRJwXpJ3tS"
   },
   "source": [
    "You can also use your own image. Uncomment and run the following cell to use your own image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "IADmNUEcJ3tS"
   },
   "outputs": [],
   "source": [
    "image = '/corral-repl/tacc/aci/PT2050/projects/PTDATAX-209/Aerial/Nunap.tif'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TqpJMo1DJ3tT"
   },
   "source": [
    "Display the downloaded image on the map."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "R3eSDY8pJ3tT"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ae09793e50454abc70940cfab0e341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=9575162.0, center=[60.894813, -162.458614], controls=(ZoomControl(options=['position', 'zoom_in_tex…"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.layers[-1].visible = False\n",
    "m.add_raster(image, layer_name=\"Image\")\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-Fwl4UJRJ3tT"
   },
   "source": [
    "## Split the image into tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "NNW62JuBJ3tT"
   },
   "outputs": [],
   "source": [
    "split_raster(image, out_dir=\"tiles\", tile_size=(3000, 3000), overlap=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OT_Djk61J3tT"
   },
   "source": [
    "## Initialize LangSAM class\n",
    "\n",
    "The initialization of the LangSAM class might take a few minutes. The initialization downloads the model weights and sets up the model for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "iFIBnMZbJ3tT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "final text_encoder_type: bert-base-uncased\n"
     ]
    }
   ],
   "source": [
    "sam = LangSAM()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zi_N0XSsJ3tT"
   },
   "source": [
    "## Specify text prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Uex9WgvnJ3tU"
   },
   "outputs": [],
   "source": [
    "text_prompt = \"building structures\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDYdZWwzJ3tU"
   },
   "source": [
    "## Segment images\n",
    "\n",
    "Part of the model prediction includes setting appropriate thresholds for object detection and text association with the detected objects. These threshold values range from 0 to 1 and are set while calling the predict method of the LangSAM class.\n",
    "\n",
    "`box_threshold`: This value is used for object detection in the image. A higher value makes the model more selective, identifying only the most confident object instances, leading to fewer overall detections. A lower value, conversely, makes the model more tolerant, leading to increased detections, including potentially less confident ones.\n",
    "\n",
    "`text_threshold`: This value is used to associate the detected objects with the provided text prompt. A higher value requires a stronger association between the object and the text prompt, leading to more precise but potentially fewer associations. A lower value allows for looser associations, which could increase the number of associations but also introduce less precise matches.\n",
    "\n",
    "Remember to test different threshold values on your specific data. The optimal threshold can vary depending on the quality and nature of your images, as well as the specificity of your text prompts. Make sure to choose a balance that suits your requirements, whether that's precision or recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "gjsXq4EiJ3tU",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing image 01 of 56: tiles/tile_0_0.tif...\n",
      "Processing image 02 of 56: tiles/tile_0_1.tif...\n",
      "Processing image 03 of 56: tiles/tile_0_2.tif...\n",
      "Processing image 04 of 56: tiles/tile_0_3.tif...\n",
      "Processing image 05 of 56: tiles/tile_0_4.tif...\n",
      "Processing image 06 of 56: tiles/tile_0_5.tif...\n",
      "Processing image 07 of 56: tiles/tile_0_6.tif...\n",
      "Processing image 08 of 56: tiles/tile_1_0.tif...\n",
      "Processing image 09 of 56: tiles/tile_1_1.tif...\n",
      "Processing image 10 of 56: tiles/tile_1_2.tif...\n",
      "Processing image 11 of 56: tiles/tile_1_3.tif...\n",
      "Processing image 12 of 56: tiles/tile_1_4.tif...\n",
      "Processing image 13 of 56: tiles/tile_1_5.tif...\n",
      "Processing image 14 of 56: tiles/tile_1_6.tif...\n",
      "Processing image 15 of 56: tiles/tile_2_0.tif...\n",
      "Processing image 16 of 56: tiles/tile_2_1.tif...\n",
      "Processing image 17 of 56: tiles/tile_2_2.tif...\n",
      "Processing image 18 of 56: tiles/tile_2_3.tif...\n",
      "Processing image 19 of 56: tiles/tile_2_4.tif...\n",
      "Processing image 20 of 56: tiles/tile_2_5.tif...\n",
      "Processing image 21 of 56: tiles/tile_2_6.tif...\n",
      "Processing image 22 of 56: tiles/tile_3_0.tif...\n",
      "Processing image 23 of 56: tiles/tile_3_1.tif...\n",
      "Processing image 24 of 56: tiles/tile_3_2.tif...\n",
      "Processing image 25 of 56: tiles/tile_3_3.tif...\n",
      "Processing image 26 of 56: tiles/tile_3_4.tif...\n",
      "Processing image 27 of 56: tiles/tile_3_5.tif...\n",
      "Processing image 28 of 56: tiles/tile_3_6.tif...\n",
      "Processing image 29 of 56: tiles/tile_4_0.tif...\n",
      "Processing image 30 of 56: tiles/tile_4_1.tif...\n",
      "Processing image 31 of 56: tiles/tile_4_2.tif...\n",
      "Processing image 32 of 56: tiles/tile_4_3.tif...\n",
      "Processing image 33 of 56: tiles/tile_4_4.tif...\n",
      "Processing image 34 of 56: tiles/tile_4_5.tif...\n",
      "Processing image 35 of 56: tiles/tile_4_6.tif...\n",
      "Processing image 36 of 56: tiles/tile_5_0.tif...\n",
      "Processing image 37 of 56: tiles/tile_5_1.tif...\n",
      "Processing image 38 of 56: tiles/tile_5_2.tif...\n",
      "Processing image 39 of 56: tiles/tile_5_3.tif...\n",
      "Processing image 40 of 56: tiles/tile_5_4.tif...\n",
      "Processing image 41 of 56: tiles/tile_5_5.tif...\n",
      "Processing image 42 of 56: tiles/tile_5_6.tif...\n",
      "Processing image 43 of 56: tiles/tile_6_0.tif...\n",
      "Processing image 44 of 56: tiles/tile_6_1.tif...\n",
      "Processing image 45 of 56: tiles/tile_6_2.tif...\n",
      "Processing image 46 of 56: tiles/tile_6_3.tif...\n",
      "Processing image 47 of 56: tiles/tile_6_4.tif...\n",
      "Processing image 48 of 56: tiles/tile_6_5.tif...\n",
      "Processing image 49 of 56: tiles/tile_6_6.tif...\n",
      "Processing image 50 of 56: tiles/tile_7_0.tif...\n",
      "Processing image 51 of 56: tiles/tile_7_1.tif...\n",
      "Processing image 52 of 56: tiles/tile_7_2.tif...\n",
      "Processing image 53 of 56: tiles/tile_7_3.tif...\n",
      "Processing image 54 of 56: tiles/tile_7_4.tif...\n",
      "Processing image 55 of 56: tiles/tile_7_5.tif...\n",
      "Processing image 56 of 56: tiles/tile_7_6.tif...\n",
      "Saved the merged prediction to masks/merged.tif.\n"
     ]
    }
   ],
   "source": [
    "sam.predict_batch(\n",
    "    images=\"tiles\",\n",
    "    out_dir=\"masks\",\n",
    "    text_prompt=text_prompt,\n",
    "    box_threshold=0.24,\n",
    "    text_threshold=0.24,\n",
    "    mask_multiplier=1,\n",
    "    dtype=\"uint8\",\n",
    "    merge=True,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YEOE_EtmJ3tU"
   },
   "source": [
    "## Visualize the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "DniXnV1lJ3tU"
   },
   "outputs": [],
   "source": [
    "mask = \"masks/merged.tif\"\n",
    "shapefile = \"Nunap.shp\"\n",
    "geosam = SamGeo(\n",
    "    model_type=\"vit_h\",\n",
    "    checkpoint=\"sam_vit_h_4b8939.pth\",\n",
    "    sam_kwargs=None,\n",
    ")\n",
    "geosam.tiff_to_vector(mask, shapefile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = \"segment.gpkg\"\n",
    "geosam.tiff_to_gpkg(mask, vector, simplify_tolerance=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "88ae09793e50454abc70940cfab0e341",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(bottom=4789702.0, center=[60.876444114650866, -162.4194180965424], controls=(ZoomControl(options=['positio…"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "style = {\n",
    "    \"color\": \"#3388ff\",\n",
    "    \"weight\": 2,\n",
    "    \"fillColor\": \"#7c4185\",\n",
    "    \"fillOpacity\": 0.5,\n",
    "}\n",
    "m.add_vector(vector, layer_name=\"Vector\", style=style)\n",
    "m"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (segment)",
   "language": "python",
   "name": "segment"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
